---
title: "Joscha Bach - Strong AI: Why we should be concerned"
image: "https:\/\/i.ytimg.com\/vi\/xqetKitv1Ko\/hqdefault.jpg"
vid_id: "xqetKitv1Ko"
categories: "Science-Technology"
tags: ["science","technology","singularity"]
date: "2021-10-29T03:47:56+03:00"
vid_date: "2017-08-21T18:13:07Z"
duration: "PT1H51M29S"
viewcount: "28720"
likeCount: "796"
dislikeCount: "20"
channel: "Science, Technology & the Future"
---
{% raw %}Title: Strong AI: Why we should be concerned about something nobody knows how to build<br />Synopsis: At the moment, nobody fully knows how to create an intelligent system that rivals or exceed human capabilities (Strong AI). The impact and possible dangers of Strong AI appear to concern mostly those futurists that are not working in day-to-day AI research. This in turn gives rise to the idea that Strong AI is merely a myth, a sci fi trope and nothing that is ever going to be implemented. The current state of the art in AI is already sufficient to lead to irrevocable changes in labor markets, economy, warfare and governance. The need to deal with these near term changes does not absolve us from considering the implications of being no longer the most intelligent beings on this planet.<br />Despite the difficulties of developing Strong AI, there is no obvious reason why the principles embedded in biological brains should be outside of the range of what our engineering can achieve in the near future. While it is unlikely that current narrow AI systems will neatly scale towards general modeling and problem solving, many of the significant open questions in developing Strong AI appear to be known and solvable.<br /><br /><br />Talk held at 'Artificial Intelligence / Human Possibilities' event as adjunct to the AGI17 conference in Melbourne 2017.<br /><br />Assessing emerging risks and opportunities in machine cognition<br /><br />With AI Experts Ben Goertzel, Marcus Hutter, Peter Cheeseman and Joscha Bach. <br /><br />Event Focus:  <br />Given significant developments in Artificial Intelligence, it's worth asking: What aspects of ideal AI have not been achieved yet?  <br />There is good reason for the growing media storm around AI - many experts agree on the big picture that with the development of Superintelligent AI (including Artificial General Intelligence) humanity will face great challenges (some polls suggest that AGI is not far).  Though in order to best manage both the opportunities and risks we need to achieve a clearer picture - this requires sensitivity to ambiguity, precision of expression and attention to theoretical detail in understanding the implications of AI, communicating/discussing AI, and ultimately engineering beneficial AI.<br /><br />Meetup details: <a rel="nofollow" target="blank" href="https://www.meetup.com/Science-Technology-and-the-Future/events/242163071/">https://www.meetup.com/Science-Technology-and-the-Future/events/242163071/</a><br /><br />Many thanks for watching!<br /><br />Consider supporting SciFuture by:<br />a) Subscribing to the SciFuture YouTube channel:  <a rel="nofollow" target="blank" href="http://youtube.com/subscription_center?add_user=TheRationalFuture">http://youtube.com/subscription_center?add_user=TheRationalFuture</a><br />b) Donating via Patreon: <a rel="nofollow" target="blank" href="https://www.patreon.com/scifuture">https://www.patreon.com/scifuture</a> and/or<br />c) Sharing the media SciFuture creates: <a rel="nofollow" target="blank" href="http://scifuture.org">http://scifuture.org</a> <br /><br />Kind regards,<br />Adam Ford<br />- Science, Technology &amp; the Future{% endraw %}
